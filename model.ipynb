{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and models used are based on: [Link Prediction in Social Networks using\n",
    "Computationally Efficient Topological Features](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=9f3c2d5364aab82a24e24e56f6013cfc4c404e13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ignore node labels as we don't want predictions to be made based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path, train_percent):\n",
    "    data = pd.read_csv(path)\n",
    "    data.head()\n",
    "    data = data.drop(['node_1', 'node_2'], axis = 'columns')\n",
    "    label = data['link_exists']\n",
    "    train_data = data.drop(['link_exists'], axis = 'columns')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, label, test_size=1-train_percent, random_state=42)\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for PyTorch (transformation from pandas dataframe to PyTorch tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_NN(x_train, y_train, x_test, y_test):\n",
    "    x_train = pd.DataFrame.to_numpy(x_train)\n",
    "    y_train = pd.Series.to_numpy(y_train)\n",
    "    x_test = pd.DataFrame.to_numpy(x_test)\n",
    "    y_test = pd.Series.to_numpy(y_test)\n",
    "\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.from_numpy(y_train).float()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).float()\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(x_train[0])\n",
    "    print(y_train[0])\n",
    "\n",
    "\n",
    "    # x_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "    # y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    # x_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "    # y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a dataframe to collect training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_data = pd.DataFrame(columns=['Dataset' ,'Model', 'Percentage of data in training', 'Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    acc_score_train = accuracy_score(y_train, model.predict(x_train))\n",
    "    acc_score_test = accuracy_score(y_test, model.predict(x_test))\n",
    "    return acc_score_train, acc_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(dataset, model, name, x_train, y_train, x_test, y_test, percentage_of_data_in_training):\n",
    "    accuracy_score_train, accuracy_score_test = train_model(model, x_train, y_train, x_test, y_test)\n",
    "    model_performance_data.loc[len(model_performance_data.index)] = [dataset, name, percentage_of_data_in_training,\n",
    "                                                                      accuracy_score_train, accuracy_score_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(12, 64)\n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.layer_3(torch.relu(self.layer_2(torch.relu(self.layer_1(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device for PyTorch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18268, 12])\n",
      "torch.Size([18268])\n",
      "torch.Size([164416, 12])\n",
      "torch.Size([164416])\n",
      "tensor([11.0000,  7.0000,  0.6061,  0.5273,  0.7857,  0.7143,  0.0000, 18.0000,\n",
      "         0.0000, 77.0000,  0.0000,  4.0000])\n",
      "tensor(0.)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([18268])) that is different to the input size (torch.Size([18268, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     27\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(x_train)\n\u001b[1;32m---> 28\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\AI\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\AI\\Lib\\site-packages\\torch\\nn\\functional.py:3145\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3143\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3148\u001b[0m     )\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([18268])) that is different to the input size (torch.Size([18268, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "data = ['data/CondMat.csv', 'data/GenRel.csv', 'data/ErdosReny.csv', 'data/BarabasiAlbert.csv']\n",
    "\n",
    "percentages = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "for dataset in data:\n",
    "    for percent in percentages:\n",
    "        x_train, y_train, x_test, y_test = prep_data(dataset, percent)\n",
    "        model = GaussianNB()\n",
    "        model_performance(dataset, model, 'GaussianNB', x_train, y_train, x_test, y_test, percent)\n",
    "        model = DecisionTreeClassifier()\n",
    "        model_performance(dataset, model, 'DecisionTreeClassifier', x_train, y_train, x_test, y_test, percent)\n",
    "        model = KNeighborsClassifier()\n",
    "        model_performance(dataset, model, 'KNeigborsClassifier', x_train, y_train, x_test, y_test, percent)\n",
    "        model = AdaBoostClassifier(algorithm='SAMME')\n",
    "        model_performance(dataset, model, 'AdaBoostClassifier', x_train, y_train, x_test, y_test, percent)\n",
    "        model = BaggingClassifier()\n",
    "        model_performance(dataset, model, 'BaggingClassifier', x_train, y_train, x_test, y_test, percent)\n",
    "        model_performance_data.head()\n",
    "        x_train, y_train, x_test, y_test = prep_data_for_NN(x_train, y_train, x_test, y_test)\n",
    "        model = NeuralNetwork()\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(100):\n",
    "            \n",
    "            outputs = model(x_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred)\n",
    "            y_pred = model(x_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            model_performance_data.loc[len(model_performance_data.index)] = [dataset, 'NeuralNetwork', percent, train_accuracy, test_accuracy]\n",
    "\n",
    "model_performance_data.to_csv('model_performance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
