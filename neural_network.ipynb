{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(features, 32)\n",
    "        self.fun1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(32, 32)\n",
    "        self.fun2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.fun3 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fun3(self.layer3(self.fun2(self.layer2(self.fun1(self.layer1(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path, percentage_in_training, to_drop):\n",
    "    to_normalize = ['neighbours_1', 'neighbours_2', 'common_neigbhours', 'total_neigbhours',\n",
    "                     'prefferential_attachment', 'friends_measure', 'shortest_path']\n",
    "\n",
    "    dataset = pd.read_csv(path)\n",
    "    features = dataset.drop('link_exists', axis='columns')\n",
    "    label = dataset['link_exists']\n",
    "    for col in to_normalize:\n",
    "        features[col] = (features[col] - features[col].min()) / (features[col].max() - features[col].min())\n",
    "    \n",
    "    features.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=1-percentage_in_training)\n",
    "    x_train = torch.tensor(x_train.to_numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = correct / len(y_true)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def model_train(model, x_train, y_train, x_test, y_test):\n",
    "    x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for i in range(50):\n",
    "        model.train()\n",
    "\n",
    "        y_logits = model(x_train).squeeze()\n",
    "        y_pred = torch.round(y_logits)\n",
    "\n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        accuracy_train = accuracy(y_train, y_pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_logits = model(x_test).squeeze()\n",
    "            y_pred = torch.round(y_logits)\n",
    "\n",
    "            test_loss = loss_fn(y_logits, y_test)\n",
    "            test_accuracy = accuracy(y_test, y_pred)\n",
    "\n",
    "    return accuracy_train, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['data/GenRel.csv', 'data/CondMat.csv', 'data/ErdosRenyi.csv', 'data/BarabasiAlbert.csv']\n",
    "percentages = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "model_performance_data = pd.DataFrame(columns=['Dataset' ,'Model', 'Percentage of data in training', 'Train Accuracy','Test Accuracy'])\n",
    "to_drop = ['node_1', 'node_2'] # 12 features\n",
    "# to_drop = ['node_1', 'node_2', 'shortest_path'] # 11 features\n",
    "# to_drop = ['node_1', 'node_2', 'shortest_path', 'density_ego_with_node_1', 'density_ego_with_node_2',\n",
    "                # 'density_ego_without_node_1', 'density_ego_without_node_2'] # 7 features\n",
    "# to_drop = ['node_1', 'node_2', 'density_ego_with_node_1', 'density_ego_with_node_2', \n",
    "                # 'density_ego_without_node_1', 'density_ego_without_node_2'] # 8 features\n",
    "\n",
    "for dataset in datasets:\n",
    "    for percentage in percentages:\n",
    "    \n",
    "        model = NeuralNetwork(12).to(device)\n",
    "        tmp = dataset.split('/')[1].split('.')[0]\n",
    "        x_train, y_train, x_test, y_test = prep_data(dataset, percentage, to_drop)\n",
    "        train_acc, test_acc = model_train(model, x_train, y_train, x_test, y_test)\n",
    "        model_performance_data.loc[len(model_performance_data)] = [tmp, 'Neural Network', percentage, train_acc, test_acc]\n",
    "        save_path = f'neuralnetworks/{tmp}/{tmp}_{percentage}.pt'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "model_performance_data.to_csv('performance/neural_network_performance_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
